import streamlit as st
from langchain.memory import ConversationBufferMemory

from wenxin import get_chat_response

st.title("ğŸ’¬ æš´èºGPT")

st.write("è™½ç„¶æˆ‘è„¾æ°”æ¯”è¾ƒæš´ï¼Œç»å¸¸é˜´é˜³æ€ªæ°”ä½ ä»¬è¿™äº›æ„šè ¢çš„äººç±»ï¼Œä½†æˆ‘ç»å¯¹é è°±")



if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(return_messages=True)
    st.session_state["messages"] = [{"role": "ai",
                                     "content": "å“Ÿï¼Ÿä»Šå¤©æ€ä¹ˆæœ‰ç©ºæ¥æ‰¾æˆ‘å•Š"}]

for message in st.session_state["messages"]:
    st.chat_message(message["role"]).write(message["content"])

prompt = st.chat_input()
if prompt:

    st.session_state["messages"].append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)

    with st.spinner("åœ¨æƒ³äº†ï¼Œä½ æœ€å¥½åˆ«å‚¬æˆ‘...."):
        response = get_chat_response(prompt, st.session_state["memory"],
                                     )
    msg = {"role": "ai", "content": response}
    st.session_state["messages"].append(msg)
    st.chat_message("ai").write(response)